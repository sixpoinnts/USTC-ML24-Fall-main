## LAB3 MINST

PB22111695 蔡孟辛

### 1 实验流程

1. 配置环境：由于requirements.txt中的torch版本与GPU的pytorch有冲突，重装环境配置了好几次。。QAQ

2. 代码部分：

   （1）GMM聚类：

   - E-step：接受数据矩阵 作为输入,根据当前的参数计算每个样本属于每个聚簇的概率,返回$\gamma$ （shape为[N, K]）

     ```py
     # 1.1 E-step: Compute the responsibilities
     # 接受数据矩阵 X 作为输入,根据当前的参数计算每个样本属于每个聚簇的概率
     # BEGIN_YOUR_CODE
     for k in range(self.n_components):
         inv_cov = np.linalg.inv(self.covs[k]) # 协方差矩阵的逆矩阵
         det = np.linalg.det(self.covs[k]) # 协方差矩阵的行列式
         pdf = self._gaussian(X, self.means[k], inv_cov, det) # 高斯概率密度函数
         gamma[:, k] = self.pi[k] * pdf # 响应度 = 混合系数 * 高斯概率密度函数
     gamma /= np.sum(gamma, axis=1, keepdims=True) # 归一化, axis=1 按行求和, keepdims=True 保持维度 
     # END_YOUR_CODE
     ```

     数学公式：$\gamma_{nk} = \frac{\pi_k \cdot \mathcal{N}(x_n | \mu_k, \Sigma_k)}{\sum_{j=1}^{K} \pi_j \cdot \mathcal{N}(x_n | \mu_j, \Sigma_j)}$

   - M-step：接受数据矩阵$X$和上面输出的 $\gamma$ 作为参数,使用最大似然估计更新模型的参数 pi 、 means 和 covs 

     ```py
     # 1.2 M-step: Update the parameters
     # BEGIN_YOUR_CODE
     for k in range(self.n_components):              
         # pi
         self.pi[k] = n_soft[k] / N
         # means
         self.means[k]  = np.sum(gamma[:, k].reshape(-1,1) * X, axis=0) / n_soft[k]
         # covs
         diff = X - self.means[k]
         self.covs[k] = (gamma[:, k][:, np.newaxis] * diff).T @ diff / n_soft[k]
         self.covs[k] += 1e-6 * np.eye(D)
     # END_YOUR_CODE
     ```

     混合系数： $\pi_k = \frac{n_k}{N} $  其中 $n_k = \sum_{n=1}^{N} \gamma_{nk} $

     均值： $ \mu_k = \frac{1}{n_k} \sum_{n=1}^{N} \gamma_{nk} x_n $

     协方差矩阵： $ \Sigma_k = \frac{1}{n_k} \sum_{n=1}^{N} \gamma_{nk} (x_n - \mu_k)(x_n - \mu_k)^T $

   （2）PCA降维（计算主成分）

   ```py
   # 2.1 Compute the principal components
   # BEGIN_YOUR_CODE
   self.mean = np.mean(X, axis=0)
   X_center = X - self.mean # 中心化数据
   cov = np.cov(X_center, rowvar=False)
   eigvals, eigvecs = np.linalg.eigh(cov) # 特征值和特征向量
   sort_eigvals = np.argsort(eigvals)[::-1] # 降序排列
   self.components = eigvecs[:, sort_eigvals[:self.dim]].T # 主成分：取前 d 个特征向量    
   # END_YOUR_CODE
   ```

   均值向量： $ \mu = \frac{1}{N} \sum_{i=1}^{N} x_i $

   中心化数据： $ X_{\text{center}} = X - \mu $

   协方差矩阵： $ \Sigma = \frac{1}{N-1} X_{\text{center}}^T X_{\text{center}} $

   特征值和特征向量： $ \Sigma v = \lambda v $

   选择前 $d$ 个特征向量： $ \text{components} = [v_1, v_2, \ldots, v_d] $

   （3）从GMM中采样

   ```py
   # 5.1
   # BEGIN_YOUR_CODE
   # 从 label 对应的高斯分布中采样一个样本
   mean = gmm.means[label]
   cov = gmm.covs[label]
   sample = np.random.multivariate_normal(mean, cov, 1)
   
   # 用 PCA 类型的 inverse_transform 方法复原回原始数据维度
   sample = pca.inverse_transform(sample)
   
   # 把这个样本处理为像素值在[0,255]范围内
   sample = np.clip(sample, 0, 255).astype(np.uint8)
   
   # shape为[H, W]的图片
   sample = sample.reshape(28, 28)
   
   # END_YOUR_CODE
   ```



### 2 调试超参数的过程

- embedding_dim : 使用PCA降维后的数据维度，一开始调大成50，发现效果不好，后来调小成6，获得较好的结果。

- use_pca : 传递以启用PCA,否则使用AutoEncoder降维（true）

- n_components : 聚簇数量,请保持为数据集的label数（不变）

- max_iter : EM算法的最大迭代次数（100 -> 300）

- results_path : 结果保存地址（不变）

- seed : 随机种子（不变）



### 3 最好的聚类和生成图片

![](E:\cylia\USTC-ML24-Fall-main\lab3\results\2024-12-10_12-50-39\cluster_ae.png)

![](E:\cylia\USTC-ML24-Fall-main\lab3\results\2024-12-10_12-50-39\cluster_pca.png)

![](E:\cylia\USTC-ML24-Fall-main\lab3\results\2024-12-10_12-50-39\cluster_tsne.png)

### 4 回答问题

- 从**训练速度**,**降维效率**,**灵活性**(eg.是否适用于各种类型的数据),**对数据分布的保持程度**,**可视化效果**这几个方面比较PCA,tSNE,AutoEncoder这三种降维方法的优劣(你可以列一个表格)

  | 比较维度             | PCA                              | tSNE                             | AutoEncoder                          |
  | -------------------- | -------------------------------- | -------------------------------- | ------------------------------------ |
  | 训练速度             | 快，但计算复杂度低               | 慢，的计算复杂度高               | 中等，取决于网络结构和数据量         |
  | 降维效率             | 高效，适用于线性可分的数据       | 高效，适用于非线性可分的数据     | 高效，适用于复杂的非线性数据         |
  | 灵活性               | 适用于各种类型的数据，但效果有限 | 适用于各种类型的数据，效果好     | 适用于各种类型的数据，效果最佳       |
  | 对数据分布的保持程度 | 保持全局结构，但可能丢失局部信息 | 保持局部结构，但可能丢失全局信息 | 与网络结构相关，可保证全局和局部信息 |
  | 可视化效果           | 一般，适用于简单数据             | 优秀，适用于复杂数据             | 优秀，适用于复杂数据                 |

- 从**生成效率**,**生成质量**,**灵活性**(eg.是否适用于各种类型的数据),**是否可控**(eg.生成指定类别的样本)这几个方面比较GMM和DDPM的优劣

  | 比较维度 | GMM                              | DDPM                             |
  | -------- | -------------------------------- | -------------------------------- |
  | 生成效率 | 快，计算复杂度低                 | 慢，计算复杂度高                 |
  | 生成质量 | 一般，适用于简单数据             | 高，适用于复杂数据               |
  | 灵活性   | 适用于各种类型的数据，但效果有限 | 适用于各种类型的数据，效果好     |
  | 是否可控 | 可控，能生成指定类别的样本       | 可控，但需要复杂的训练和采样过程 |

  

### 5 .反馈

作业花费时间：4days